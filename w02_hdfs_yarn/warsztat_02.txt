Warsztat 02

HDFS

0. Zaloguj się na NameNode (maszyna master)
	(using putty ssh)
	
0a. Gdzie jest konfiguracja Hadoopa ?
	/etc/hadoop/conf/

0b. Jaka jest wersja Javy na maszynie ?
	java -version
	
0c. Jak sprawdzić wersję Hadoopa ?
	hadoop version

	
1. Zapoznaj się z interfejsem WWW NameNode
<master_public_dns>:50070
1a. Gdzie są informacje o datanodach?
	DataNodes bar xD
	
1b. Czy można sprawdzić dane w filesystemie?
	TAK :O Utilities -> Browse files

1c. Sprawdź route <master_public_dns>:50070/jmx
	Big as fuck JSON

1d. Jakie statystyki są dostępne ?
	Failures, snapshots, data usage (in bytes and percent), number of used nodes, history, logs

	
2. W jakim katalogu przechowywany jest fsimage na NameNode ?
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///mnt/namenode,file:///mnt1/namenode</value>
  </property>

  in hdfs-site.xml

  
3(*). W jaki sposób dane są przechowywane na DataNode ? (do tego ćwiczenia musisz się przelogować przez NameNode) / opcjonalne

Hint:
aby swobodnie korzystać z tych poleceń przeloguj się na konto hdfs:
sudo su - hdfs


4. Zapoznaj się z poleceniami:
Co dzięki nim możesz zrobić ?

4a. hdfs dfs
	appendToFile (append one file to another)
	
4b. hdfs fsck
	HDFS supports the fsck command to check for various inconsistencies. Does not repair. NameNode should do the repairs.
	
4c. hdfs dfsadmin
	admin window - look reports, manage cache, blocks etc.
	
4d. hdfs haadmin
	manage namenodes - check which is active and standby, make one active etc.

	
5. Sprawdź:
5a. ile aktualnie zajmuje cały filesystem HDFS ?
	~400MB per machine
	
5b. ile jest wszystkich plików w HDFS?
	309988
	
5c. Gdzie można znaleźć jeszcze te informacje ?
	From console, probaby somewhere on web

	
6. Utwórz lokalnie katalog z kilkoma plikami z randomową treścią - skopiuj go na HDFS
7. Zmień replikację wszystkich plików na 10
8. Odczytaj zawartość uprzednio skopiownaych plików bezpośrednio z HDFS
9. Skopiuj katalog z uprzednio przekopiowanymi plikami do lokalnego katalogu /tmp/data_from_hdfs
10. Usuń cały katalog z HDFS z uprzednio utworzonymi danymi


YARN

1. Zapoznaj się z interfejsem WWW ResourceManagera
<master_public_dns>:8088
1a. Gdzie są informacje o nodemanagerach?
1b. Sprawdź route /jmx
1c. Jakie statystyki są dostępne ?
1d. Sprawdź route /conf
1e. Gdzie można sprawdzić informacje o schedulerze ?

2. Zapoznaj się z poleceniami:
2a. yarn application
2b. yarn jar
2c. yarn logs
2d. yarn queue
2e. yarn rmadmin

3. Zapoznaj się z poleceniem:
yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar

4. Uruchom przykładową aplikacje obliczająca Pi metodą quasi monte carlo.
4a. Zwróć uwagę na to co się dzieje w ResourceManager
4b. Pobierz oraz zapoznaj się z logami ukończonej aplikacji.
4c. Uruchom aplikację pononwnie oraz "zabij" aplikację podczas jej działania (po uruchomieniu joba naciśnij Ctrl-C)
(parametry do monte carlo: 100 10000)

5. Uruchom program wordCount na pliku pan_tadeusz.txt
(s3://kompleksowe-szkolenie-bigdata/warsztat_02/pan_tadeusz.txt)
