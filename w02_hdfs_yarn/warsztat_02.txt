Warsztat 02

HDFS

0. Zaloguj się na NameNode (maszyna master)
	(using putty ssh)
	
0a. Gdzie jest konfiguracja Hadoopa ?
	/etc/hadoop/conf/

0b. Jaka jest wersja Javy na maszynie ?
	java -version
	
0c. Jak sprawdzić wersję Hadoopa ?
	hadoop version

	
1. Zapoznaj się z interfejsem WWW NameNode
<master_public_dns>:50070
1a. Gdzie są informacje o datanodach?
	DataNodes bar xD
	
1b. Czy można sprawdzić dane w filesystemie?
	TAK :O Utilities -> Browse files

1c. Sprawdź route <master_public_dns>:50070/jmx
	Big as fuck JSON

1d. Jakie statystyki są dostępne ?
	Failures, snapshots, data usage (in bytes and percent), number of used nodes, history, logs

	
2. W jakim katalogu przechowywany jest fsimage na NameNode ?
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///mnt/namenode,file:///mnt1/namenode</value>
  </property>

  in hdfs-site.xml

  
3(*). W jaki sposób dane są przechowywane na DataNode ? (do tego ćwiczenia musisz się przelogować przez NameNode) / opcjonalne

Hint:
aby swobodnie korzystać z tych poleceń przeloguj się na konto hdfs:
sudo su - hdfs


4. Zapoznaj się z poleceniami:
Co dzięki nim możesz zrobić ?

4a. hdfs dfs
	appendToFile (append one file to another)
	
4b. hdfs fsck
	HDFS supports the fsck command to check for various inconsistencies. Does not repair. NameNode should do the repairs.
	
4c. hdfs dfsadmin
	admin window - look reports, manage cache, blocks etc.
	
4d. hdfs haadmin
	manage namenodes - check which is active and standby, make one active etc.

	
5. Sprawdź:
5a. ile aktualnie zajmuje cały filesystem HDFS ?
	hdfs dfs -du -h -s /
	~400MB per machine (400*2=800)
	
5b. ile jest wszystkich plików w HDFS?
	hdfs dfs -count /
	309988
	
5c. Gdzie można znaleźć jeszcze te informacje ?
	From console, probaby somewhere on web

	
6. Utwórz lokalnie katalog z kilkoma plikami z randomową treścią - skopiuj go na HDFS
	for i in `seq 1 20`; do cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 10000 | head -n 1 > example_file_$i; done
	hdfs dfs -ls /user/hadoop
	hdfs dfs -put ./example_file_* /user/hadoop/
	hdfs dfs -ls /user/hadoop
	
	
7. Zmień replikację wszystkich plików na 10
	hdfs dfs -setrep -R 10 /. (in this directory)
	OR
	<property> 
		<name>dfs.replication<name> 
		<value>3<value> 
		<description>Block Replication<description> 
	<property>
	in hdfs-site.xml

	
8. Odczytaj zawartość uprzednio skopiownaych plików bezpośrednio z HDFS
	hdfs dfs -cat *

	
9. Skopiuj katalog z uprzednio przekopiowanymi plikami do lokalnego katalogu /tmp/data_from_hdfs
	mkdir /tmp/data_from_hdfs
	hdfs dfs -get /user/hadoop/* /tmp/data_from_hdfs

	
10. Usuń cały katalog z HDFS z uprzednio utworzonymi danymi
	hdfs dfs -rm -r  /user/hadoop/*

YARN

1. Zapoznaj się z interfejsem WWW ResourceManagera
<master_public_dns>:8088
1a. Gdzie są informacje o nodemanagerach?
	Nodes bar
	
1b. Sprawdź route /jmx
	Another big fucking json
	
1c. Jakie statystyki są dostępne ?
	Memory used/avalible, containers, virtual cores, 
	
1d. Sprawdź route /conf
	This time big fucking XML
	
1e. Gdzie można sprawdzić informacje o schedulerze ?
	Scheduler bar

2. Zapoznaj się z poleceniami:
2a. yarn application
	runs application
	
2b. yarn jar
	runs jar
	
2c. yarn logs
	chekcs logs
	
2d. yarn queue
	checks queue
	
2e. yarn rmadmin
	clean process in case of failure

	
3. Zapoznaj się z poleceniem:
yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar


4. Uruchom przykładową aplikacje obliczająca Pi metodą quasi monte carlo.
	yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi 10 1000
	
4a. Zwróć uwagę na to co się dzieje w ResourceManager
	Application appeared with status, id, etc
	
4b. Pobierz oraz zapoznaj się z logami ukończonej aplikacji.
	yarn logs -applicationId application_1543306082330_0001

4c. Uruchom aplikację pononwnie oraz "zabij" aplikację podczas jej działania (po uruchomieniu joba naciśnij Ctrl-C)
(parametry do monte carlo: 100 10000)

5. Uruchom program wordCount na pliku pan_tadeusz.txt
(s3://kompleksowe-szkolenie-bigdata/warsztat_02/pan_tadeusz.txt)
	hdfs dfs -mkdir /user/hadoop/pan_tadeusz
	hdfs dfs -cp s3://kompleksowe-szkolenie-bigdata/warsztat_02/pan_tadeusz.txt /user/hadoop/pan_tadeusz
	hdfs dfs -ls /user/hadoop/pan_tadeusz
	yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount
	yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount /user/hadoop/pan_tadeusz /user/hadoop/pan_tadeusz_wordcount
	hdfs dfs -text /user/hadoop/pan_tadeusz_wordcount/* | sort | uniq | sort -k2 -n
